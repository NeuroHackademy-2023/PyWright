{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# the main function wgr_deconv_canonhrf_par iterates through each voxel's data, applies event detection, adjusts event onsets, and performs deconvolution. \n## It returns the deconvolved data, event information, estimated HRF, adjustment values, and parameter estimates.\n\nimport numpy as np\nimport scipy as sps\n\n#takes input data and returns deconvolved data, event onset, estimated HRF, adjustment values, parameter estimates\n\n##data: Input data matrix with dimensions (time points x number of voxels)\n##thr: Threshold value for detecting events\n##event_lag_max: Maximum time from neural event to BOLD event in bins\n##TR: Time resolution (time between data points) in seconds\n\ndef wgr_deconv_canonhrf_par(data, thr, event_lag_max, TR):\n    N, nvar = data.shape\n    even_new = wgr_trigger_onset(data, thr)\n    p_m = 3\n    T = round(30 / TR)\n    data_deconv = np.zeros((N, nvar))\n    HRF = np.zeros((T, nvar))\n    PARA = np.zeros((3, nvar))\n    data_deconv, HRF, event, adjust_global, PARA = [], [], [], [], []\n    for i in range(nvar):\n        data_deconv_i, HRF_i, event_i, adjust_global_i, PARA_i = wgr_adjust_onset(\n            data[:, i], even_new[i], event_lag_max, TR, p_m, T, N\n        )\n        data_deconv.append(data_deconv_i)\n        HRF.append(HRF_i)\n        event.append(event_i)\n        adjust_global.append(adjust_global_i)\n        PARA.append(PARA_i)\n    return data_deconv, event, HRF, adjust_global, PARA\n\n#performs the adjustment and deconvolution steps for each voxel\ndef wgr_adjust_onset(dat, even_new, event_lag_max, TR, p_m, T, N):\n    kk = 1\n    hrf = np.zeros((T, event_lag_max + 1))\n    Cov_E = np.zeros(event_lag_max + 1)\n    for event_lag in range(event_lag_max + 1):\n        RR = even_new - event_lag\n        RR = RR[RR > 0]\n        design = np.zeros(N)\n        design[RR - 1] = 1\n        hrf[:, kk - 1], e3, param_kk = Fit_Canonical_HRF(dat, TR, design, T, p_m)\n        Cov_E[kk - 1] = np.cov(e3)\n        kk += 1\n    ind = np.argmin(Cov_E)\n    ad_global = ind - 1\n    even_new -= ad_global\n    even_new = even_new[even_new > 0]\n    hrf = hrf[:, ind - 1]\n    param = param_kk[:, ind - 1]\n    H = np.fft.fft(np.vstack((hrf, np.zeros((N - T, 1)))), axis=0)\n    M = np.fft.fft(dat)\n    dat_deconv = np.fft.ifft(\n        np.conj(H) * M / (H * np.conj(H) + Cov_E[ind - 1]), axis=0\n    ).real\n    return dat_deconv, hrf, even_new, ad_global, param\n\n#detects event onsets in the input data matrix and returns a list of event onsets for each voxel\ndef wgr_trigger_onset(matrix, thr):\n    N, nvar = matrix.shape\n    matrix = (matrix - np.mean(matrix, axis=0)) / np.std(matrix, axis=0)\n    oneset = []\n    for i in range(nvar):\n        oneset_temp = []\n        for t in range(1, N - 1):\n            if (\n                matrix[t, i] > thr\n                and matrix[t - 1, i] < matrix[t, i]\n                and matrix[t, i] > matrix[t + 1, i]\n            ):\n                oneset_temp.append(t)\n        oneset.append(oneset_temp)\n    return oneset\n\n#fits GLM using the canonical HRF and its derivatives\ndef Fit_Canonical_HRF(tc, TR, Run, T, p):\n    len_Run = len(Run)\n    X = np.zeros((len_Run, p))\n    h, dh, dh2 = CanonicalBasisSet(TR)\n    v = np.convolve(Run, h)[:len_Run]\n    X[:, 0] = v\n    if p > 1:\n        v = np.convolve(Run, dh)[:len_Run]\n        X[:, 1] = v\n    if p > 2:\n        v = np.convolve(Run, dh2)[:len_Run]\n        X[:, 2] = v\n    X = np.column_stack((np.zeros(len_Run) + 1, X))\n    b = np.linalg.pinv(X) @ tc\n    e = tc - X @ b\n    fit = X @ b\n    b = b[1:]\n    if p == 2:\n        bc = np.sign(b[0]) * np.sqrt(b[0] ** 2 + b[1] ** 2)\n        H = np.column_stack((h, dh))\n    elif p == 1:\n        bc = b[0]\n        H = h\n    elif p > 2:\n        bc = np.sign(b[0]) * np.sqrt(b[0] ** 2 + b[1] ** 2 + b[2] ** 2)\n        H = np.column_stack((h, dh, dh2))\n    hrf = H @ b\n    param = get_parameters2(hrf, T)\n    return hrf, e, param\n\n#generates canonical HRF and derivatives\ndef CanonicalBasisSet(TR):\n    len_h = round(30 / TR)\n    v1 = np.ones(len_h)\n    v2 = v1 - np.convolve(v1, np.array([1, -1]), \"valid\")\n    v3 = v2 - np.convolve(v2, np.array([1, -1]), \"valid\")\n    h = v1 / np.max(v1)\n    dh = v2 / np.max(v2)\n    dh2 = v3 / np.max(v3)\n    return h, dh, dh2\n\n# calculates model parameters (height, time to peak, and width) for the estimated HRF\ndef get_parameters2(hdrf, t):\n    n = int(round(t * 0.8))\n    h, p = np.max(np.abs(hdrf[:n])), np.argmax(np.abs(hdrf[:n])) + 1\n    if h > 0:\n        v = hdrf >= h / 2\n    else:\n        v = hdrf <= h / 2\n    b = np.diff(v.astype(int))\n    w = np.sum(b > 0)\n    cnt = p - 2\n    g = hdrf[1:] - hdrf[:-1]\n    while cnt >= 0 and np.abs(g[cnt]) < 0.001:\n        h = hdrf[cnt]\n        p = cnt + 1\n        cnt -= 1\n    param = np.array([h, p, w])\n    return param\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}