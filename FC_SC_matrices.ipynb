{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacob/opt/anaconda3/lib/python3.7/site-packages/nilearn/input_data/__init__.py:27: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-41044bd30726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     client=S3Client(\n\u001b[1;32m     16\u001b[0m         \u001b[0mlocal_cache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         profile_name='hcp'))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/cloudpathlib/s3/s3client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, aws_access_key_id, aws_secret_access_key, aws_session_token, no_sign_request, botocore_session, profile_name, boto3_session, file_cache_mode, local_cache_dir, endpoint_url, boto3_transfer_config, content_type_method, extra_args)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             self.sess = Session(\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0maws_access_key_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maws_access_key_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0maws_secret_access_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maws_secret_access_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Session' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from cloudpathlib import S3Path, S3Client\n",
    "import nibabel as nib \n",
    "import neuropythy as ny\n",
    "from nilearn import datasets, input_data, connectome\n",
    "import numpy as np\n",
    "\n",
    "# Make sure that we have a cache path:\n",
    "cache_path = Path('/tmp/cache')\n",
    "if not cache_path.exists():\n",
    "    cache_path.mkdir()\n",
    "\n",
    "hcp_base_path = S3Path(\n",
    "    's3://hcp-openaccess/HCP_1200/',\n",
    "    client=S3Client(\n",
    "        local_cache_dir=cache_path,\n",
    "        profile_name='hcp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hcp_base_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-46515257a015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhcp_subdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhcp_base_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# There are about 1200 of these, so we won't show them all, just the first 10:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhcp_subdirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hcp_base_path' is not defined"
     ]
    }
   ],
   "source": [
    "hcp_subdirs = list(hcp_base_path.iterdir())\n",
    "# There are about 1200 of these, so we won't show them all, just the first 10:\n",
    "hcp_subdirs[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nibabel.cifti2.cifti2.Cifti2Image at 0x7fa0f31be3b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load preprocessed fMRI data\n",
    "sub115825 = 'shared/HCP/115825/MNINonLinear/Results/rfMRI_REST1_7T_PA/rfMRI_REST1_7T_PA_Atlas_1.6mm_hp2000_clean.dtseries.nii'\n",
    "subj_bold = ny.load(sub115825)\n",
    "subj_bold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(lh_data_bold, rh_data_bold, subcortex_data_bold) = ny.hcp.cifti_split(subj_bold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 59292)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BOLD signal for every vertex\n",
    "lh_data_bold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 59292)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh_data_bold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 62053)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subcortex_data_bold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "sub115825_labels = 'shared/HCP/115825/MNINonLinear/fsaverage_LR59k/115825.aparc.59k_fs_LR.dlabel.nii'\n",
    "subj_labels = nib.load(sub115825_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(lh_data_labels, rh_data_labels, subcortex_data_labels) = ny.hcp.cifti_split(subj_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 59292)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label ID for every vertex\n",
    "lh_data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 59292)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh_data_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through every unique label \n",
    "# for every label find the vertices with that label\n",
    "# average BOLD signal for all the vertices\n",
    "## ==> smaller matrix, 900 x number of labels (about 50 maybe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 59292)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge BOLD signals and labels together\n",
    "lh_data = np.vstack((lh_data_bold, lh_data_labels))\n",
    "lh_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "       27., 28., 29., 30., 31., 32., 33., 34., 35., nan])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique lh label\n",
    "unique_lh = np.unique(lh_data_labels)\n",
    "unique_lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_lh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e52e42c34c1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## loop through unique labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_lh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlh_data_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlh_data_bold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# identify the vertices with label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_lh' is not defined"
     ]
    }
   ],
   "source": [
    "### Generate N x t 2D matrix of mean BOLD signal for each subject\n",
    "\n",
    "avg_lh_bold_mat = []\n",
    "\n",
    "# loop through unique lh labels\n",
    "for label in unique_lh[unique_lh != 0]: # for each label that isn't 0\n",
    "    label_idx = np.where(lh_data_labels == label)[1] # get the index of the vertices that match this label\n",
    "    label_timeseriesda = np.mean(lh_data_bold[:, label_idx], axis = 1) # take the mean of the vertices within the region\n",
    "    avg_lh_bold_mat.append(label_timeseriesda) # append the mean BOLD signal of this region at each time point (volume)\n",
    "avg_lh_bold_mat = np.vstack(avg_lh_bold_mat) # stack all the regions together into a matrix\n",
    "\n",
    "avg_rh_bold_mat = []\n",
    "\n",
    "# loop through unique rh labels\n",
    "for label in unique_rh[unique_rh != 0]: # do the same in the RH\n",
    "    label_idx = np.where(rh_data_labels == label)[1]\n",
    "    label_timeseriesda = np.mean(rh_data_bold[:, label_idx], axis = 1)\n",
    "    avg_rh_bold_mat.append(label_timeseriesda)  \n",
    "avg_rh_bold_mat = np.vstack(avg_rh_bold_mat) \n",
    "\n",
    "avg_bold_mat = np.vstack((avg_lh_bold_mat, avg_rh_bold_mat)) # stack the LH and RH matrices together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate N x N FC matrix for each subject\n",
    "subj_bold_data = subj_bold.get_fdata()\n",
    "\n",
    "num_regions = avg_bold_mat.shape[0]\n",
    "FC_mat = np.zeros((num_regions, num_regions)) # intialize empty matrix\n",
    "\n",
    "# loop through each region index\n",
    "for i_region in range(num_regions): # for each region (x-axis)\n",
    "    for j_region in range(num_regions): # and for each region (y-axis)\n",
    "        if i_region == j_region: \n",
    "            FC_mat == 0 # the correlation between the region and itself is set to 0 by convention\n",
    "        else: # otherwise compute the pearson correlation between the time series of each region with every other region\n",
    "            FC_mat[i, j] = pearsonr(subj_bold_data[:, i_region], subj_bold_data[:, j_region])[0]\n",
    "\n",
    "FC_mat_fisherz = np.arctanh(FC_mat) # to make the distribution of the values more normal, fisher-z transform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 59292)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh_data = np.vstack((rh_data_bold, rh_data_labels))\n",
    "rh_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0., 36., 37., 38., 40., 41., 42., 43., 44., 45., 46., 47., 48.,\n",
       "       49., 50., 51., 52., 53., 54., 55., 56., 57., 58., 59., 60., 61.,\n",
       "       62., 63., 64., 65., 66., 67., 68., 69., 70., nan])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_rh = np.unique(rh_data_labels)\n",
    "unique_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge labels together\n",
    "all_data_labels = np.hstack((lh_data_labels, rh_data_labels))\n",
    "all_data_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "       27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 40.,\n",
       "       41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53.,\n",
       "       54., 55., 56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66.,\n",
       "       67., 68., 69., 70., nan])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique labels\n",
    "unique_labels = np.unique(all_data_labels)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FC_matrix = np.zeros((len(all_data_bold),len(unique_labels)))\n",
    "average_bold_list = []\n",
    "\n",
    "for label in unique_labels:\n",
    "    # Find vertices with the current label\n",
    "    label_vertices = np.where(all_data_labels == label)[0]\n",
    "    \n",
    "    # Get the BOLD signal for vertices with the current label\n",
    "    label_bold = all_data_bold[label_vertices]\n",
    "    \n",
    "    # Calculate the average BOLD signal along the first axis (vertices)\n",
    "    average_bold = np.mean(label_bold, axis=0)\n",
    "    \n",
    "    average_bold_list.append(average_bold)\n",
    "    \n",
    "FC_matrix = np.array(average_bold_list).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118584, 70)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FC_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'which'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## loop through unique labels\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m unique_lh:\n\u001b[0;32m----> 5\u001b[0m     label_vertices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhich\u001b[49m(lh_data_labels \u001b[38;5;241m==\u001b[39m label)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# identify the vertices with label\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#label_bold = lh_data_bold[label_vertices] # extract BOLD for the vertices\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#avg_lh_bold = np.mean(label_bold, axis=0) # average BOLD \u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m#avg_lh_bold_label.append(avg_lh_bold) \u001b[39;00m\n\u001b[1;32m     10\u001b[0m avg_lh_bold_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(avg_lh_bold_label) \u001b[38;5;66;03m# each row corresponds to the avg BOLD for each unique label \u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'which'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vertices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/numpy/core/_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "avg_bold_label = []\n",
    "\n",
    "## loop through unique labels\n",
    "for label in unique_labels:\n",
    "    label_vertices = np.where(all_data_labels == label)[0] # identify the vertices with label\n",
    "    label_bold = all_data_bold[label_vertices] # extract BOLD for the vertices\n",
    "    avg_bold = np.mean(label_bold, axis=0) # average BOLD \n",
    "    avg_bold_label.append(avg_bold) \n",
    "    \n",
    "avg_bold_label = np.array(avg_bold_label) # each row corresponds to the avg BOLD for each unique label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11089.08984375, 12419.76953125, 13332.8515625 , ...,\n",
       "        12756.04003906, 11879.54101562, 12271.46972656],\n",
       "       [11089.08984375, 12419.76953125, 13332.8515625 , ...,\n",
       "        12756.04003906, 11879.54101562, 12271.46972656],\n",
       "       [11089.08984375, 12419.76953125, 13332.8515625 , ...,\n",
       "        12756.04003906, 11879.54101562, 12271.46972656],\n",
       "       ...,\n",
       "       [11089.08984375, 12419.76953125, 13332.8515625 , ...,\n",
       "        12756.04003906, 11879.54101562, 12271.46972656],\n",
       "       [11089.08984375, 12419.76953125, 13332.8515625 , ...,\n",
       "        12756.04003906, 11879.54101562, 12271.46972656],\n",
       "       [           nan,            nan,            nan, ...,\n",
       "                   nan,            nan,            nan]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bold_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ignore from here (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose Atlas\n",
    "atlas = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "# atlas = sub115825.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Masking Object\n",
    "masker = input_data.NiftiLabelsMasker(labels_img=atlas.maps, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/joblib/memory.py:353: FutureWarning: The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.\n",
      "  return self.func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Extract time-series for each ROIs\n",
    "time_series = masker.fit_transform(sub115825)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.8119864  0.9464104  ... 0.7323204  0.611148   0.5107898 ]\n",
      " [0.8119864  1.         0.8052994  ... 0.8699405  0.6637082  0.56077397]\n",
      " [0.9464104  0.8052994  1.         ... 0.7288159  0.63289195 0.47462818]\n",
      " ...\n",
      " [0.7323204  0.8699405  0.7288159  ... 1.         0.68419755 0.48319957]\n",
      " [0.611148   0.6637082  0.63289195 ... 0.68419755 1.         0.6632808 ]\n",
      " [0.5107898  0.56077397 0.47462818 ... 0.48319957 0.6632808  1.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/nilearn/connectome/connectivity_matrices.py:495: FutureWarning: The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.\n",
      "  covariances_std = [\n"
     ]
    }
   ],
   "source": [
    "# Correlation FC matrix\n",
    "correlation_matrix = connectome.ConnectivityMeasure(kind='correlation').fit_transform([time_series])[0]\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub100610_freesurfer_path = hcp_base_path / '100610' / 'T1w' / '100610'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we want to load one of these files into nibabel, we can convert it\n",
    "# into a filesystem path (cloudpaths cannot just be passed to nibabel).\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "brain_img_path = sub100610_freesurfer_path / 'mri' / 'brain.mgz'\n",
    "brain_img = nib.load(brain_img_path.fspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'S3Path' object has no attribute 'fetch_atlas_msdl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Selecting ROIs using masks\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m msdl_atlas \u001b[38;5;241m=\u001b[39m \u001b[43mhcp_base_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_atlas_msdl\u001b[49m()\n\u001b[1;32m      7\u001b[0m msdl_coords \u001b[38;5;241m=\u001b[39m msdl_atlas\u001b[38;5;241m.\u001b[39mregion_coords\n\u001b[1;32m      8\u001b[0m n_regions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(msdl_coords)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'S3Path' object has no attribute 'fetch_atlas_msdl'"
     ]
    }
   ],
   "source": [
    "# Selecting ROIs using masks\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "msdl_atlas = hcp_base_path.fetch_atlas_msdl()\n",
    "\n",
    "msdl_coords = msdl_atlas.region_coords\n",
    "n_regions = len(msdl_coords)\n",
    "\n",
    "print(f'MSDL has {n_regions} ROIs, part of the following networks :\\n{np.unique(msdl_atlas.networks)}.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
